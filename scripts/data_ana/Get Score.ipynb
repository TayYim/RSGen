{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get score\n",
    "\n",
    "Of an ADS\n",
    "\n",
    "After running the evaluate_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "import pickle\n",
    "import math\n",
    "# from env_utils import read_pso_search_files, detect_convergence\n",
    "%matplotlib inline\n",
    "\n",
    "from data_utils import find_match_from_seach_collector, get_unique_search_df, get_time_diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_adv_score(ttc):\n",
    "    if ttc == 0:\n",
    "        collision = 1\n",
    "    else:\n",
    "        collision = 0\n",
    "    if ttc > 10:\n",
    "        ttc = 10\n",
    "    A = ttc - collision * 50\n",
    "    A = (A - -50) / (10 - -50) \n",
    "    A = A*100\n",
    "    return A\n",
    "\n",
    "def get_single_average_score(exp_path):\n",
    "    search_df_unique = get_unique_search_df(exp_path)\n",
    "    search_df = search_df_unique.tail(20)\n",
    "    scores = []\n",
    "    for i, row in search_df.iterrows():\n",
    "        ttc = row[\"ttc\"]\n",
    "        scores.append(calculate_adv_score(ttc))\n",
    "    average_score = np.mean(scores)\n",
    "    return average_score\n",
    "\n",
    "def K(omega):\n",
    "    mu = 0.5\n",
    "    sigma = 0.1\n",
    "    return math.exp(-((omega - mu) ** 2) / (2 * sigma ** 2))\n",
    "\n",
    "def get_single_scenario_score(score_w_dict):\n",
    "    part_a = 0\n",
    "    part_b = 0\n",
    "    for w, score in score_w_dict.items():\n",
    "        part_a += K(w) * score\n",
    "    part_b = sum([K(w) for w in score_w_dict.keys()])\n",
    "    \n",
    "    return part_a/part_b\n",
    "\n",
    "def get_single_scenario_score_wo_K(score_w_dict):\n",
    "    part_a = 0\n",
    "    part_b = 0\n",
    "    for w, score in score_w_dict.items():\n",
    "        part_a += score\n",
    "    part_b = len(score_w_dict)\n",
    "    \n",
    "    return part_a/part_b\n",
    "\n",
    "def get_single_scenario_score_wo_side(score_w_dict):\n",
    "    # without w=0.0 and 1.0\n",
    "    part_a = 0\n",
    "    part_b = 0\n",
    "    for w, score in score_w_dict.items():\n",
    "        if w == 0.0 or w == 1.0:\n",
    "            continue\n",
    "        part_a += score\n",
    "    part_b = len(score_w_dict) - 2\n",
    "    \n",
    "    return part_a/part_b\n",
    "\n",
    "def get_single_scenario_score_wo_middle(score_w_dict):\n",
    "    # without w=0.3 ,0.5 and 0.7\n",
    "    part_a = 0\n",
    "    part_b = 0\n",
    "    for w, score in score_w_dict.items():\n",
    "        if 0.2 < w < 0.8:\n",
    "            continue\n",
    "        part_a += score\n",
    "    part_b = len(score_w_dict) - 3\n",
    "    \n",
    "    return part_a/part_b\n",
    "\n",
    "def get_single_scenario_score_only_high(score_w_dict):\n",
    "    # 0.7, 1.0\n",
    "    part_a = 0\n",
    "    part_b = 0\n",
    "    for w, score in score_w_dict.items():\n",
    "        if w < 0.7:\n",
    "            continue\n",
    "        part_a += score\n",
    "    part_b = 2\n",
    "    \n",
    "    return part_a/part_b\n",
    "\n",
    "def get_single_scenario_score_only_high(score_w_dict):\n",
    "    # 0.7, 1.0\n",
    "    part_a = 0\n",
    "    part_b = 0\n",
    "    for w, score in score_w_dict.items():\n",
    "        if w < 0.7:\n",
    "            continue\n",
    "        part_a += score\n",
    "    part_b = 2\n",
    "    \n",
    "    return part_a/part_b\n",
    "\n",
    "def get_single_scenario_score_only_high_K(score_w_dict):\n",
    "    # 0.7, 1.0\n",
    "    ws = [0.7, 1.0]\n",
    "    part_a = 0\n",
    "    part_b = 0\n",
    "    for w, score in score_w_dict.items():\n",
    "        if w not in ws:\n",
    "            continue\n",
    "        part_a +=  K(w) * score\n",
    "    part_b = sum([K(w) for w in ws])\n",
    "    \n",
    "    return part_a/part_b\n",
    "\n",
    "def get_single_scenario_score_only_low(score_w_dict):\n",
    "    # 0.0, 0.3\n",
    "    part_a = 0\n",
    "    part_b = 0\n",
    "    for w, score in score_w_dict.items():\n",
    "        if w > 0.3:\n",
    "            continue\n",
    "        part_a += score\n",
    "    part_b = 2\n",
    "    \n",
    "    return part_a/part_b\n",
    "\n",
    "def get_single_scenario_score_only_low_K(score_w_dict):\n",
    "    # 0.0, 0.3\n",
    "    ws = [0.0, 0.3]\n",
    "    part_a = 0\n",
    "    part_b = 0\n",
    "    for w, score in score_w_dict.items():\n",
    "        if w not in ws:\n",
    "            continue\n",
    "        part_a += K(w)*score\n",
    "    part_b = sum([K(w) for w in ws])\n",
    "    \n",
    "    return part_a/part_b\n",
    "\n",
    "def get_single_scenario_score_only_0(score_w_dict):\n",
    "    # 0.0\n",
    "    part_a = 0\n",
    "    part_b = 0\n",
    "    for w, score in score_w_dict.items():\n",
    "        if w != 0.0:\n",
    "            continue\n",
    "        part_a += score\n",
    "    part_b = 1\n",
    "    \n",
    "    return part_a/part_b\n",
    "\n",
    "def get_single_scenario_score_only_half(score_w_dict):\n",
    "    # 0.5\n",
    "    part_a = 0\n",
    "    part_b = 0\n",
    "    for w, score in score_w_dict.items():\n",
    "        if w != 0.5:\n",
    "            continue\n",
    "        part_a += score\n",
    "    part_b = 1\n",
    "    \n",
    "    return part_a/part_b\n",
    "\n",
    "def get_single_scenario_score_only_1(score_w_dict):\n",
    "    # 1.0\n",
    "    part_a = 0\n",
    "    part_b = 0\n",
    "    for w, score in score_w_dict.items():\n",
    "        if w != 1.0:\n",
    "            continue\n",
    "        part_a += score\n",
    "    part_b = 1\n",
    "    \n",
    "    return part_a/part_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_score(score_fn, score_dict):\n",
    "    # score for each scenario\n",
    "    scenario_score_dict = {}\n",
    "\n",
    "    for scenario_name, w_dict in score_dict.items():\n",
    "        scenario_score_dict[scenario_name] = score_fn(w_dict)\n",
    "\n",
    "    scenario_name_list = [\"front_brake\", \"front_cut_in_with_one_npc\", \"front_cut_in_with_two_npc\",\n",
    "                        \"opposite_vehicle_taking_priority\",\n",
    "                        \"nonsignalized_junction_left_turn\",\n",
    "                        \"nonsignalized_junction_right_turn\"]\n",
    "    # Show the score for each scenario\n",
    "    print(\"===========Average for each scenario:============\")\n",
    "    for scenario_name in scenario_name_list:\n",
    "        print(scenario_name, round(scenario_score_dict[scenario_name],2))\n",
    "\n",
    "    # Final score\n",
    "    final_score_average = np.mean(list(scenario_score_dict.values()))\n",
    "    final_score_average = round(final_score_average, 2)\n",
    "    print(\"=======================\")\n",
    "    print(f\"Overall average:{final_score_average}\")\n",
    "    return final_score_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agent_score(agent_name, base_path):\n",
    "    score_dict = {}\n",
    "\n",
    "    ADS_name = agent_name\n",
    "\n",
    "    # Traverse the output directory\n",
    "    for scenario_name in os.listdir(base_path):\n",
    "        score_dict[scenario_name] = {}\n",
    "        # Check if it is a directory\n",
    "        scenario_path = os.path.join(base_path, scenario_name)\n",
    "        if os.path.isdir(scenario_path):\n",
    "            # Traverse the agent directory under each scenario\n",
    "            HAS_AGENT_DIR = False\n",
    "            for dir_name in os.listdir(scenario_path):\n",
    "                if ADS_name == dir_name:\n",
    "                    HAS_AGENT_DIR = True\n",
    "                    break\n",
    "\n",
    "            if HAS_AGENT_DIR:\n",
    "                for agent_name in os.listdir(scenario_path):\n",
    "                    if ADS_name == agent_name:\n",
    "                        agent_path = os.path.join(scenario_path, agent_name)\n",
    "                        scenario_path = agent_path\n",
    "                        break\n",
    "\n",
    "            for experiment_name in os.listdir(scenario_path):\n",
    "\n",
    "                w = float(experiment_name.split('_')[1])\n",
    "\n",
    "                score_dict[scenario_name][w] = 0\n",
    "\n",
    "                exp_path = os.path.join(scenario_path, experiment_name)\n",
    "\n",
    "                average_score = get_single_average_score(Path(exp_path))\n",
    "\n",
    "                score_dict[scenario_name][w] = average_score   \n",
    "\n",
    "    # # Show the second layer structure of the dict\n",
    "    for k, v in score_dict.items():\n",
    "        print(k)\n",
    "        for k2, v2 in v.items():\n",
    "            print(k2, v2)\n",
    "        print()\n",
    "                \n",
    "    cols = ['ADS','Purposed Method',\t'w/o K',\t'w/o 0.0,1.0',\t'w/o 0.3-0.7',\t'High Risks Only',\n",
    "            'Low Risks Only',\t'0.0 only',\t'0.5 only',\t'1.0 only',\t\n",
    "            'High Risks Only K',\t'Low Risks Only K']\n",
    "    \n",
    "    scores_by_method = [ADS_name]\n",
    "    print(\"\\n>>>>>>>>>>Original Method<<<<<<<<<<\")\n",
    "    scores_by_method.append(make_score(get_single_scenario_score, score_dict))\n",
    "    # scores_by_method.append(make_score(get_single_scenario_score_wo_K, score_dict))\n",
    "    # scores_by_method.append(make_score(get_single_scenario_score_wo_side, score_dict))\n",
    "    # scores_by_method.append(make_score(get_single_scenario_score_wo_middle, score_dict))\n",
    "    # scores_by_method.append(make_score(get_single_scenario_score_only_high, score_dict))\n",
    "    # scores_by_method.append(make_score(get_single_scenario_score_only_low, score_dict))\n",
    "    print(\"\\n>>>>>>>>>>Low Risk Only<<<<<<<<<<\")\n",
    "    scores_by_method.append(make_score(get_single_scenario_score_only_0, score_dict))\n",
    "    # scores_by_method.append(make_score(get_single_scenario_score_only_half, score_dict))\n",
    "    print(\"\\n>>>>>>>>>>High Risk Only<<<<<<<<<<\")\n",
    "    scores_by_method.append(make_score(get_single_scenario_score_only_1, score_dict))\n",
    "    # scores_by_method.append(make_score(get_single_scenario_score_only_high_K, score_dict))\n",
    "    # scores_by_method.append(make_score(get_single_scenario_score_only_low_K, score_dict))\n",
    "\n",
    "    return scores_by_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nonsignalized_junction_left_turn\n",
      "0.7 12.855\n",
      "0.3 12.664166666666667\n",
      "1.0 25.525\n",
      "0.5 83.9075\n",
      "0.0 81.37249999999999\n",
      "\n",
      "front_cut_in_with_two_npc\n",
      "0.7 93.40083333333334\n",
      "0.0 70.0\n",
      "0.5 99.2475\n",
      "0.3 90.29083333333334\n",
      "1.0 78.45083333333335\n",
      "\n",
      "opposite_vehicle_taking_priority\n",
      "0.5 85.45833333333334\n",
      "0.7 64.48666666666666\n",
      "0.3 90.88416666666666\n",
      "1.0 88.705\n",
      "0.0 97.05249999999998\n",
      "\n",
      "front_cut_in_with_one_npc\n",
      "0.3 87.74083333333333\n",
      "0.0 91.51666666666667\n",
      "1.0 96.955\n",
      "0.5 58.388333333333335\n",
      "0.7 99.0725\n",
      "\n",
      "front_brake\n",
      "1.0 75.74249999999999\n",
      "0.7 71.43666666666665\n",
      "0.3 35.839999999999996\n",
      "0.0 83.18583333333333\n",
      "0.5 88.25083333333333\n",
      "\n",
      "nonsignalized_junction_right_turn\n",
      "1.0 60.23166666666666\n",
      "0.5 51.70166666666667\n",
      "0.3 30.479999999999997\n",
      "0.0 40.44833333333333\n",
      "0.7 60.16166666666667\n",
      "\n",
      "\n",
      ">>>>>>>>>>Original Method<<<<<<<<<<\n",
      "===========Average for each scenario:============\n",
      "front_brake 80.88\n",
      "front_cut_in_with_one_npc 65.85\n",
      "front_cut_in_with_two_npc 97.67\n",
      "opposite_vehicle_taking_priority 83.8\n",
      "nonsignalized_junction_left_turn 68.75\n",
      "nonsignalized_junction_right_turn 50.34\n",
      "=======================\n",
      "Overall average:74.55\n",
      "\n",
      ">>>>>>>>>>Low Risk Only<<<<<<<<<<\n",
      "===========Average for each scenario:============\n",
      "front_brake 83.19\n",
      "front_cut_in_with_one_npc 91.52\n",
      "front_cut_in_with_two_npc 70.0\n",
      "opposite_vehicle_taking_priority 97.05\n",
      "nonsignalized_junction_left_turn 81.37\n",
      "nonsignalized_junction_right_turn 40.45\n",
      "=======================\n",
      "Overall average:77.26\n",
      "\n",
      ">>>>>>>>>>High Risk Only<<<<<<<<<<\n",
      "===========Average for each scenario:============\n",
      "front_brake 75.74\n",
      "front_cut_in_with_one_npc 96.96\n",
      "front_cut_in_with_two_npc 78.45\n",
      "opposite_vehicle_taking_priority 88.7\n",
      "nonsignalized_junction_left_turn 25.52\n",
      "nonsignalized_junction_right_turn 60.23\n",
      "=======================\n",
      "Overall average:70.94\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "12 columns passed, passed data had 4 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/pandas/core/internals/construction.py:939\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 939\u001b[0m     columns \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_or_indexify_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/pandas/core/internals/construction.py:986\u001b[0m, in \u001b[0;36m_validate_or_indexify_columns\u001b[0;34m(content, columns)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi_list \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(content):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;66;03m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[0;32m--> 986\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns passed, passed data had \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    989\u001b[0m     )\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_mi_list:\n\u001b[1;32m    991\u001b[0m     \u001b[38;5;66;03m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 12 columns passed, passed data had 4 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[944], line 13\u001b[0m\n\u001b[1;32m      7\u001b[0m s_apollo_7 \u001b[38;5;241m=\u001b[39m get_agent_score(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapollo\u001b[39m\u001b[38;5;124m\"\u001b[39m, Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../output-eva-apollo-7\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      9\u001b[0m cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mADS\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPurposed Method\u001b[39m\u001b[38;5;124m'\u001b[39m,\t\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw/o K\u001b[39m\u001b[38;5;124m'\u001b[39m,\t\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw/o 0.0,1.0\u001b[39m\u001b[38;5;124m'\u001b[39m,\t\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw/o 0.3-0.7\u001b[39m\u001b[38;5;124m'\u001b[39m,\t\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHigh Risks Only\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLow Risks Only\u001b[39m\u001b[38;5;124m'\u001b[39m,\t\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0.0 only\u001b[39m\u001b[38;5;124m'\u001b[39m,\t\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0.5 only\u001b[39m\u001b[38;5;124m'\u001b[39m,\t\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1.0 only\u001b[39m\u001b[38;5;124m'\u001b[39m,\t\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHigh Risks Only K\u001b[39m\u001b[38;5;124m'\u001b[39m,\t\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLow Risks Only K\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 13\u001b[0m all_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms_highway\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_ba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_interfuser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_tfpp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_apollo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_apollo_8\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_apollo_7\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# drop index\u001b[39;00m\n\u001b[1;32m     15\u001b[0m all_df \u001b[38;5;241m=\u001b[39m all_df\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/pandas/core/frame.py:806\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    805\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m--> 806\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m \u001b[43mnested_data_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[1;32m    808\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[1;32m    809\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    812\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    814\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    815\u001b[0m         arrays,\n\u001b[1;32m    816\u001b[0m         columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    819\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    820\u001b[0m     )\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/pandas/core/internals/construction.py:520\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    518\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fields)\n\u001b[0;32m--> 520\u001b[0m arrays, columns \u001b[38;5;241m=\u001b[39m \u001b[43mto_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/pandas/core/internals/construction.py:845\u001b[0m, in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    842\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m    843\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _list_to_arrays(data)\n\u001b[0;32m--> 845\u001b[0m content, columns \u001b[38;5;241m=\u001b[39m \u001b[43m_finalize_columns_and_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/pandas/core/internals/construction.py:942\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    939\u001b[0m     columns \u001b[38;5;241m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[0;32m--> 942\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[1;32m    945\u001b[0m     contents \u001b[38;5;241m=\u001b[39m convert_object_array(contents, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mValueError\u001b[0m: 12 columns passed, passed data had 4 columns"
     ]
    }
   ],
   "source": [
    "# s_highway = get_agent_score(\"highway\", Path(\"../../output-final\"))\n",
    "# s_ba = get_agent_score(\"ba\", Path(\"../../output-final\"))\n",
    "# s_interfuser = get_agent_score(\"interfuser\", Path(\"../../output-final\"))\n",
    "# s_tfpp = get_agent_score(\"tfpp\", Path(\"../../output-final\"))\n",
    "# s_apollo = get_agent_score(\"apollo\", Path(\"../../output-eva-apollo-9-uc39\"))\n",
    "# s_apollo_8 = get_agent_score(\"apollo\", Path(\"../../output-eva-apollo-8\"))\n",
    "s_apollo_7 = get_agent_score(\"apollo\", Path(\"../../output-eva-apollo-7\"))\n",
    "\n",
    "cols = ['ADS','Purposed Method',\t'w/o K',\t'w/o 0.0,1.0',\t'w/o 0.3-0.7',\t'High Risks Only',\n",
    "        'Low Risks Only',\t'0.0 only',\t'0.5 only',\t'1.0 only',\t\n",
    "        'High Risks Only K',\t'Low Risks Only K']\n",
    "\n",
    "all_df = pd.DataFrame([s_highway, s_ba, s_interfuser, s_tfpp, s_apollo, s_apollo_8, s_apollo_7], columns=cols)\n",
    "# drop index\n",
    "all_df = all_df.reset_index(drop=True)\n",
    "display(all_df)\n",
    "# save csv\n",
    "all_df.to_csv(\"score_by_type.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
